{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import tqdm\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "import ray\n",
    "import openai\n",
    "import ast\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedundantParenthesesRemover(ast.NodeTransformer):\n",
    "    def visit_Expr(self, node):\n",
    "        self.generic_visit(node)\n",
    "        if isinstance(node.value, ast.BinOp):\n",
    "            return node.value\n",
    "        return node\n",
    "\n",
    "def remove_redundant_parentheses(expression):\n",
    "    # Parse the expression\n",
    "    parsed_expression = ast.parse(expression)\n",
    "\n",
    "    # Remove redundant parentheses\n",
    "    transformer = RedundantParenthesesRemover()\n",
    "    transformed_expression = transformer.visit(parsed_expression)\n",
    "\n",
    "    # Convert the transformed expression back to a string\n",
    "    simplified_expression = ast.unparse(transformed_expression)\n",
    "\n",
    "    return simplified_expression\n",
    "    \n",
    "def divide(a, b):\n",
    "    return f\"({a} / {b})\"\n",
    "\n",
    "def subtract(a, b):\n",
    "    return f\"({a} - {b})\"\n",
    "\n",
    "def multiply(a, b):\n",
    "    return f\"({a} * {b})\"\n",
    "\n",
    "def add(a, b):\n",
    "    return f\"({a} + {b})\"\n",
    "\n",
    "def exp(a, b):\n",
    "    return f\"({a} ** {b})\"\n",
    "\n",
    "def greater(a, b):\n",
    "    return f\"({a} > {b})\"\n",
    "\n",
    "def translate_expr(expr):\n",
    "    if \"table\" in expr:\n",
    "        return expr\n",
    "    \n",
    "    # replace const_m1\n",
    "    expr = re.sub(r'const_m1', r'-1', expr)\n",
    "\n",
    "    # change % to / 100\n",
    "    expr = re.sub(r'([0-9]*\\.?[0-9]+)%', r'divide(\\1 , 100)', expr)\n",
    "    \n",
    "    expr = re.sub(r'const_([0-9]*\\.?[0-9]+)', r'\\1', expr)\n",
    "    try:\n",
    "        new_expr = eval(expr)\n",
    "        new_expr = remove_redundant_parentheses(new_expr)\n",
    "    except Exception as e:\n",
    "        print(e, expr)\n",
    "        new_expr = expr\n",
    "    \n",
    "    return new_expr\n",
    "\n",
    "def convert_to_markdown(data):\n",
    "    markdown = \"|\"\n",
    "    \n",
    "    # Add table headers\n",
    "    for header in data[0]:\n",
    "        markdown += header + \"|\"\n",
    "    markdown += \"\\n|\"\n",
    "    \n",
    "    # Add table header separators\n",
    "    for _ in data[0]:\n",
    "        markdown += \"---|\"\n",
    "    markdown += \"\\n\"\n",
    "    \n",
    "    # Add table rows\n",
    "    for row in data[1:]:\n",
    "        markdown += \"|\"\n",
    "        for cell in row:\n",
    "            markdown += cell + \"|\"\n",
    "        markdown += \"\\n\"\n",
    "        \n",
    "    return markdown\n",
    "\n",
    "def extract_answer(response):\n",
    "    # extract content inside Calculate()\n",
    "    matches = re.findall(r\"Calculate\\(([\\(\\)0-9 ><,\\.\\/\\+\\-\\*]*)\\)\", response)\n",
    "    if len(matches) == 0:\n",
    "        if \"Yes\" in response:\n",
    "            return \"Yes\"\n",
    "        elif \"No\" in response:\n",
    "            return \"No\"\n",
    "        else:\n",
    "            return \"\"\n",
    "    else:\n",
    "        output = matches[0].replace(\",\", \"\")\n",
    "        return output\n",
    "    \n",
    "def if_exec_correct(t_prog, g_prog):\n",
    "    try:\n",
    "        t_exec = eval(t_prog)\n",
    "\n",
    "        if type(t_exec) == bool and g_prog in [\"Yes\", \"No\"]:\n",
    "            t_exec = \"Yes\" if t_exec else \"No\"\n",
    "\n",
    "            if t_exec == g_prog:\n",
    "                return True\n",
    "            \n",
    "        g_exec = eval(g_prog)\n",
    "\n",
    "        if t_exec == g_exec:\n",
    "            return True\n",
    "        elif t_exec * 100 == g_exec:\n",
    "            return True\n",
    "        elif t_exec * 100 == -g_exec:\n",
    "            return True\n",
    "        elif t_exec == g_exec * 100:\n",
    "            return True\n",
    "        elif t_exec == -g_exec * 100:\n",
    "            return True\n",
    "        elif t_exec * 1000000 == g_exec:\n",
    "            return True\n",
    "        elif t_exec * 1000000 == -g_exec:\n",
    "            return True\n",
    "        elif t_exec == g_exec * 1000000:\n",
    "            return True\n",
    "        elif t_exec == -g_exec * 1000000:\n",
    "            return True\n",
    "        elif t_exec == -g_exec:\n",
    "            return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\"decapoda-research/llama-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = torch.load(\"./llama-65b/checkpoint-500/hf_llama.pth\", map_location=\"cpu\")\n",
    "# model = LlamaForCausalLM.from_pretrained(\"decapoda-research/llama-65b-hf\", device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "# model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "                \"You need to answer the user's question in the ### Question ### section.\\n\" \\\n",
    "                \"You need to provide the answer in the format 'Calculate(a + b)', where the expression needs to be python excutable.\" \\\n",
    "                # \"You can calculate the average of a column by using the function 'Average(table_column_name)'.\\n\" \\\n",
    "                # \"Similarly, you can calculate the sum, the maximum, the minimum, the count of a column by using the functions \"\\\n",
    "                # \"'Sum(table_column_name)', 'Max(table_column_name)', 'Min(table_column_name)', 'Count(table_column_name)' respectively.\\n\" \\\n",
    "                # \"You only use the table's column name inside those operations\\n\" \\\n",
    "                \"For example, if the question is 'What is the sum of 1 + 2?', you need to answer 'Calc(1 + 2)'.\" \\\n",
    "                \"if the question is 'Is 123 greater than 231?', you need to answer 'Calc(123 > 231)'.\" \\\n",
    "                # \"|Age|\\n|---|\\n|12|\\n|15|\\n|16|\\n\\n What is the average age? The answer is 'Calculate(Average(Age))'\" \\\n",
    "                \"DO NOT give anything else other than'Calculate()'.\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [00:00<00:00, 14194.32it/s]\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../FinQA/dataset/test.json\"\n",
    "\n",
    "with open(filepath) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "programs = []\n",
    "translated_programs = []\n",
    "answers = []\n",
    "\n",
    "for item in tqdm.tqdm(data):\n",
    "    table_md = convert_to_markdown(item[\"table_ori\"])\n",
    "    question = item[\"qa\"][\"question\"]\n",
    "    \n",
    "    pre_text = \"\\n\".join(item[\"pre_text\"])\n",
    "    post_text = \"\\n\".join(item[\"post_text\"])\n",
    "\n",
    "    programs.append(item[\"qa\"][\"program_re\"])\n",
    "    translated_programs.append(translate_expr(item[\"qa\"][\"program_re\"]))\n",
    "    answers.append(item[\"qa\"][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./results/llama65b-finetune-300.json\") as f:\n",
    "#     results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = results[\"responses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_programs = []\n",
    "\n",
    "for response in responses:\n",
    "    gen_programs.append(extract_answer(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 (92710000-86842000)/86842000 | (100690000-92710000)/92710000\n",
      "13 281.09>286.22 | 281.09>228.97\n",
      "15 table_average(netchangefortheyear,none) | (4648+3625+1620)/3\n",
      "18 15.3/(139549/1000) | 15.3/139549\n",
      "19 9.7+10.2+(25.0+24.0) | 25.0+9.7\n",
      "20 (772-843)/843 | (843-772)/772\n",
      "22 (101.88-93.21)/93.21 | (101.54-101.88)/101.88\n",
      "29 3500/3081 | 3081/136\n",
      "32 table_max(provisionforincometaxes,none) | \n",
      "33 3087/55687 | 0.51/(2.5+0.51)\n",
      "34 61912-367 | 367+51.0\n",
      "35 168-56 | 168+56\n",
      "38 4.6+5.5+2 | 166+166+166\n",
      "44 (950.4+(957.4+769.1))/3 | (950.4+(957.4+769.1)+3)/2\n",
      "47 (559.7-515.2)/559.7 | (765.2-559.7)/559.7\n",
      "48 10.4/61.4*100 | 10354/61.4\n",
      "53 3/401362 | 3.0*1000/401362\n",
      "57 10.8/112.7 | 112.7/10.8\n",
      "59 411636+439000 | (556000+(411636+439000)+3)/2\n",
      "61 294/30 | -23/30\n",
      "62 1211143*308.1 | 1217121*308.1\n",
      "63 155+-141+4 | 38-155\n",
      "67 49447/59801 | 10354/59801\n",
      "75 11.02/9.52/9.52 | (11.02-9.52)/9.52\n",
      "78 78227+81808 | \n",
      "79 207.62/97.13 | 207.62-97.13\n",
      "80 207.62-97.13 | 207.62-107.76\n",
      "81 37/1.4 | 37/1000000\n",
      "82 102400/15790 | 102400/27524\n",
      "83 74360/180993 | 74360/(180993+74360)\n",
      "84 (1.11+1.08)/1.08 | (1.11-1.08)/1.08\n",
      "87 2*1000000/2779 | 2/411636\n",
      "88 368-68 | (368-68)/68\n",
      "92 table_average(operatingincome,none) | \n",
      "93 426932-341003 | 426932-345777\n",
      "95 362400+2000 | 362400+256+149768\n",
      "99 7532/180993 | 158578/180993*100\n",
      "103 (713*42-762*41)/(762*41) | (713-762)/762\n",
      "105 table_average(endingbalance,none) | \n",
      "106 945.5/(1.4*1000) | 945.5/12.1\n",
      "114 table_sum(worldwide,none) | (586+3057+236)/3\n",
      "115 367+78 | 581-729\n",
      "116 table_sum(total,none) | \n",
      "118 (37.79-31.16)/31.16 | (39.6-24.19)/24.19\n",
      "120 53818+-36528+157 | 53818-27229\n",
      "122 327/184/327 | 184/327\n",
      "124 ((208.14-100)/100)**(1/5)-1 | (208.14-100)**(1/5-1)-1\n",
      "134 217692/139255 | 217692*1000000\n",
      "141 (2.36-2.25)*100 | 2.5-2.36\n",
      "144 5829+(187+95) | 5829-(187+95)\n",
      "152 (4-3.9)/4*100 | (3.9-4.0)/3.9*100\n",
      "154 1.8*64.2 | 1.8*64.2+1.9*66.64+2.0*64.54\n",
      "157 126+111+112 | 112/1178\n",
      "159 100/3 | 10/3\n",
      "160 110000000+10000000 | 110000000/(9.99/100)\n",
      "165 (257685+230323+206017)/3 | (257685+230323+206017+3)/2\n",
      "166 (161.43-150.27)/150.27 | (150.27-120.6)/120.6\n",
      "168 table_max(tier2capital,none) | \n",
      "169 332/10591 | 1573/10591\n",
      "170 4.9*-1/3.7 | (3.7-3.5)/3.5\n",
      "172 table_min(cashinstruments,none) | \n",
      "174 table_sum(otherafrica,none) | \n",
      "178 table_sum(distillates,none) | \n",
      "182 45686*37.73 | 6015*40.51+5145*38.94+34526*37.07\n",
      "183 128.16/100 | (128.16-100)/100\n",
      "186 44.11-39.03 | (44.11-39.03)/39.03\n",
      "188 22825000+49250000 | 49250000-50.0\n",
      "189 table_average(operatingprofit,none) | \n",
      "190 4.7-3.3 | \n",
      "191 11*33.32-13*26.93 | 33.32+26.93\n",
      "194 20/23 | 330/20*100\n",
      "199 1.074/1.209 | 781/1.2\n",
      "200 (385+383+380)/3 | (2.0+2.0+2.0+3)/2\n",
      "203 57800/163000 | 57100/163000\n",
      "204 (500.0-240.9)/240.9 | (250.0-258.6)/258.6\n",
      "207 2449.9/15191.5 | 866.1/2449.9\n",
      "210 11.8/146.1 | 9.6/146.1\n",
      "212 8.75/6.91*8.75 | 8.05*(4.97/100)*10\n",
      "216 41.9-4.8 | 41.9-27.5\n",
      "220 table_average(totalassets,none) | \n",
      "223 2.13/100*64.2 | 2.13/1.8\n",
      "225 19+12 | 711-12\n",
      "227 1.42/(1+25/100) | 1.76-24/100\n",
      "228 630/700 | 630/7083\n",
      "230 (378-419)/419 | (419-378)/378\n",
      "231 (31-24)/24 | (24-31)/31\n",
      "232 171.8+0.4 | 171.8+172.8+158.7\n",
      "234 707-48.87 | 707*48.87\n",
      "244 (96.67-100)/100 | (121.04-100)/100\n",
      "247 503000/298 | 173000/60\n",
      "248 24700/101500 | 26900/122300\n",
      "250 5/4*5 | 5*1000+7\n",
      "252 808043/3700106 | 808043/3316258\n",
      "260 (-5205--1636)/-1636 | (1636-146)/146\n",
      "261 (235.63-104.23)/104.23 | (83.69-100)/100-(104.24-100)/100\n",
      "263 (108.7+138.0+127.1-127.1)/127.1 | 127.1/148.9-1\n",
      "264 table_max(provisionforcreditlosses,none) | \n",
      "265 163000/57800/163000 | 57100/163000\n",
      "268 table_max(ultimatetrendrate,none) | \n",
      "270 (107-66)/66 | 66/107\n",
      "276 21+99 | 99-21\n",
      "278 19/(63+81) | 19/(81+19)\n",
      "281 384102+121417-(381415+65439) | 384102-381415\n",
      "283 1220-1214 | 1224-1220\n",
      "292 (58219-71267)/71267 | (71267-58219)/58219\n",
      "297 (17.7-19.1)/19.1 | (22.3-28.3)/28.3\n",
      "298 ((73+(104+61))/2+3)/2 | (73+(104+61))/3\n",
      "300 (-291--599)/-599 | (89-99)/99\n",
      "302 3.4+2.2 | 23000+0.1\n",
      "306 13.3+5.4 | 7517-5016\n",
      "307 (155-148)/148 | (378-155)/155\n",
      "313 8/2-1 | 8*(4/100)-2\n",
      "315 342.9+78.5 | (342.9+78.5)/1000\n",
      "316 ((370.32-100)/100)**(1/5)-1 | 194.06+(370.32-100)**(1/5-1)-1\n",
      "323 (665-1.2*1000)/(1.2*1000) | (665-88)/88*100\n",
      "324 (100690000-92710000)/92710000 | (10069000-92710000)/92710000\n",
      "325 318063-60224 | 318063-110457\n",
      "326 332/121 | 15/121\n",
      "328 (4.5-4.25)*400.0*1000000 | 3.5*1000000-400.0*(4.25/100)\n",
      "330 7327-20963 | 1743-20963\n",
      "332 1328-176 | 1334-176\n",
      "335 table_average(initialhealthcaretrendrate,none) | \n",
      "339 (28.8-30.3)/30.3 | (26.2-28.8)/28.8\n",
      "346 (43+47)/2 | \n",
      "347 table_sum(vestedduringtheyear,none) | 490475*1000000*3\n",
      "348 60.6-100/22 | 51052+48609\n",
      "349 (9981+6788)/93033 | 9.5*1000/93.0\n",
      "353 171.8+0.4 | 171.8+1.5\n",
      "356 2327.2/12988.7 | 2327.2/13981.9\n",
      "359 58219-71267 | 908+3468-489\n",
      "360 17057.4-16772.9 | (17057.4-16772.9)/16772.9\n",
      "361 2.6/(35/100) | 2.6-1000\n",
      "362 242/(242+177947) | 242/177947\n",
      "366 (40.51+38.94)/2 | (40.51+38.94+37.07)/3\n",
      "367 (44.72+34.25)/2 | (60.15+41.3+2)/2\n",
      "374 (265+172)/2 | 265-172\n",
      "379 32.73/(1+6/100) | 32.73/(100+6/100)\n",
      "381 665-2239-2239 | (2239-823)/823\n",
      "383 (473.6-139.8)/473.6 | (139.8+252.0)/473.6\n",
      "384 2.9/900.1 | 900.1/2.9\n",
      "389 8985-11057 | (8985-11057)/11057\n",
      "395 table_min(collateralposted,none) | \n",
      "396 239.5/802.6 | 165.7/617.9\n",
      "398 (100-13)/100*2.93 | 3.77/(100-28/100)\n",
      "399 750/500*100 | (750+500)/(11664+11665)*100\n",
      "402 63/(63+81) | 81/(81+63)\n",
      "403 0.6+0.1 | 0.6+0.1+0.1\n",
      "406 (1.6-2.3)/2.3 | (2.3-0.4)/0.4\n",
      "409 (10558+6426)/23556 | (7363+10558)/23556\n",
      "412 table_max(foreigncurrencytranslation,none) | \n",
      "418 (621.6-666.9)/666.9 | (30.5-22.366)/22.366\n",
      "419 665-2239 | 2239-823\n",
      "423 39/4 | 116/15\n",
      "424 table_sum(total,none) | 2365+2500+2538\n",
      "427 231/6304 | 231/5009\n",
      "428 4333146-1837 | 1837-780\n",
      "430 46.7-38.9-38.9 | 46.7-38.9\n",
      "439 1400/(5/100) | 289/(5/100)\n",
      "441 30+1 | 23*-1-292\n",
      "442 9.45/(1+23/100) | 9.45/(100-23)*100\n",
      "443 1.7*100/7.75 | 1.7*(100/8.25)\n",
      "450 8.0/100-4.7/100 | 8.0-4.7\n",
      "453 100/10 | 100/3\n",
      "454 29+32+13 | 38+21+5\n",
      "459 4630/46780 | 0.51/(0.51+1.22)\n",
      "460 5.5/100+70.6/100 | 70.7/100*70.6\n",
      "461 (800+700+192)/(800+700+300) | 151.7-32.7\n",
      "463 (22.366-12.393)/12.393 | 22.366-12.393\n",
      "468 13+24+49 | 4904-5051\n",
      "470 table_max(derivatives,none) | \n",
      "472 76.0+(1.3+2)/2 | 76.0/100+77.3/100\n",
      "474 90/1594 | 1594/1594\n",
      "475 6.22/(1+7/100) | 13/(100-7)*7\n",
      "483 1-5687/6275 | 13/(5687-6275)\n",
      "488 897*(50/100) | 897*(33/100)\n",
      "492 8000/(8000+8000+8000) | 8000/(8000+1000)\n",
      "493 (64+(90+77))/3 | (90+77+64+3)/2\n",
      "498 table_max(netderivativeliabilitiesunderbilateralagreements,none) | \n",
      "499 table_max(netderivativeliabilitiesunderbilateralagreements,none) | \n",
      "503 (195237-177947)/177947 | 195237-180993\n",
      "504 64/54 | 54/64\n",
      "507 829*(29/100) | 829-83\n",
      "508 34/3669 | 208/3669\n",
      "514 1088+1105+945 | (1088+1105+945)/1000\n",
      "516 5/6.2 | 5/1.8\n",
      "517 174335/(17984+2248) | 2248/17984\n",
      "518 43.81-100-(74.57-100) | (43.81-100)/100-(74.57-100)/100\n",
      "522 342.9/(342.9+78.5) | (342.9+78.5)/(342.9+78.5)\n",
      "525 (325.1-400.0)/400.0 | 253907/3543016\n",
      "527 56616/146915 | 59584*1000000*56616\n",
      "528 (11589+(50131+(23596+63003))+4)/2 | 23596+63003+50131\n",
      "531 10/9 | 10-9\n",
      "548 (104-87)/87 | 8717/8304-1\n",
      "553 3.87/100*(3.87/100/(2.56/100)) | 3.87/100*3.87\n",
      "555 31.16-24.57 | 35.3-24.57\n",
      "561 15477-6040 | (6271-6040)/6271\n",
      "562 (3.0+(2.1+3.7))/3 | \n",
      "564 10919/(7*1000) | 799/981*100\n",
      "570 6882/70842 | 6882/77724\n",
      "571 3008-3084 | 3008--3084\n",
      "572 (2.3+4.6+9.2)/3 | (2.3+4.6+9.2+3)/2\n",
      "573 1.8/5.6 | 1.8/11.2\n",
      "574 table_average(structuredcommercialloanvehicles,none) | (5.3+7.2)/2\n",
      "578 209/191/191 | (209-191)/191\n",
      "579 (2.6-2.2)/2.2 | 2.6/2.2\n",
      "581 (666.9-577.8)/577.8 | (22.366-6.006)/6.006\n",
      "583 335000*159.35 | 205000*160.2/1000000\n",
      "588 table_average(liabilities,none) | \n",
      "590 (6.6+3.7)/426.6 | 426.6/426.6\n",
      "591 25400/16200 | 1800/3200\n",
      "594 (320-271)/271 | 367-47\n",
      "599 126.6/70.5-1-(214.4/126.6-1) | 214.4/126.6-1\n",
      "601 5.8+6.3 | 5.8-6.3\n",
      "610 9.5*(33/100) | 9.5/1000*1000\n",
      "612 table_average(endofyear,none) | \n",
      "613 (35.1-32.8)/32.8 | 254.1-225.2\n",
      "615 (109.8-1000000)/2616618 | 32.1*1000000/2616618\n",
      "616 (198.05-146.97)/146.97 | (146.97-100)/100\n",
      "618 63003-50131 | (63003-50131)/50131\n",
      "619 table_average(netsales,none) | \n",
      "623 635/1000 | 634.9*1000/94\n",
      "626 -4096>891 | 70000>65000\n",
      "627 (7729*(21/100)-5038*(14/100))/(5038*(14/100)) | (7729*(21/100)-5400*(13/100))/(5400*(13/100))\n",
      "628 180+291 | 151>180\n",
      "632 36.3/100-32.9/100 | 32.9-36.3\n",
      "636 13.4/14.7 | 8.0/13.4\n",
      "637 1597+816 | 816+1597+1089+538\n",
      "641 (119-86+86)/2 | (119-86)/86\n",
      "642 177.26-151.16-151.16 | (177.26-151.16)/151.16\n",
      "646 258.6-250.0-1.4 | 250.0*(7.875/100)/10000058*(7.875/100)/10000058\n",
      "652 150+175+2756 | 2756+(150+175)+(150+175)\n",
      "656 (531.8+243.5)/1020.1 | 531.8/1020.1\n",
      "662 27/5041 | (5014-5225)/5225\n",
      "666 (29.26-24.57)/24.57 | (29.26-19.78)/19.78\n",
      "668 1-89/99 | (99-89)/99\n",
      "669 0.4/0.8 | 0.4/772\n",
      "670 (500.0-240.9)/240.9 | (240.9-2251.2)/2251.2\n",
      "671 (29.7-21.0)/21.0 | 29.7-21.0\n",
      "672 2229188*100/2.5 | 1619553*(2.5/100)\n",
      "677 (169-138)/138 | (39-138)/138\n",
      "678 259.5+0.2 | 0.2/617.9\n",
      "683 (581-367)/581 | 367-581\n",
      "686 515.2+250 | 765.2-250\n",
      "687 12300+17000+2800+47800 | 73200+17000+2800\n",
      "691 32800/113300 | 4800/15800\n",
      "705 (33.93-24.98)/24.98 | (48886-53210)/53210\n",
      "706 27+37 | 27+37+14\n",
      "710 table_average(netunrealizedinvestmentgains,none) | \n",
      "713 (145095+(56616+217692)+3)/2 | (56616+217692+145095)/3\n",
      "714 932*0.44 | 932*0.44/100\n",
      "716 (9.09-5.15)/5.15 | (5.15-9.09)/9.09\n",
      "725 (30.56+35.61)/2 | (30.56+34.52)/2\n",
      "726 2690/18988 | 2690/28383\n",
      "729 table_sum(asphalt,none) | 74+75+78\n",
      "730 480*(27/100) | 480-829\n",
      "734 (28114-31947)/31947 | (107551-28114)/28114\n",
      "735 4934+28524 | 28524-4934\n",
      "736 149768+450000 | 149768+450000+400000\n",
      "745 200*1000000*(7.375/100) | 200*(7.375/100)/2\n",
      "750 43.9*1000000 | 43.9>5754\n",
      "763 table_sum(developmentcostsincurredduringtheperiod,none) | \n",
      "766 divide(3465,table_sum(total,none)) | 3828/562\n",
      "767 5/100-3/100 | 3292/(5/100)\n",
      "768 108/619 | 31/619\n",
      "771 378/1782 | 18+1782\n",
      "773 511.7/605.5 | 511.7/798.3\n",
      "778 2180592-51410 | 2101604-2180592\n",
      "781 (8959-8717)/8717 | (8959-8304)/8304\n",
      "784 1546-7327 | 20963-2005\n",
      "785 1224-1214 | 1219+1221+1224\n",
      "789 table_min(effectivetaxrate,none) | \n",
      "790 2728290/2912456 | (23000-0.1)/0.1\n",
      "791 (309183+(217692+145095))/3 | (217692+145095+309183+3)/2\n",
      "792 table_average(settlements,none) | \n",
      "793 (8.8-1.0)/1.0 | (1.0-8.8)/8.8\n",
      "803 (64.8-1000000)/1.11 | 1860000*1.11\n",
      "805 420.5/750.0 | 750.0/420.5\n",
      "807 29/(29+4)-8/(8+2) | 29/11-1\n",
      "809 (3.09-3.2)/3.2 | (2806-2723)/2723\n",
      "810 2408+1364 | 3772+1364\n",
      "811 200+500+750 | 75048+(200+500)\n",
      "814 105/190 | 105/289\n",
      "815 (236-3057)/3057 | (586-3057)/586\n",
      "816 table_average(expectedvolatility,none) | \n",
      "817 7/4.7 | 7/(4.7-7)\n",
      "821 8.8-2.9 | 2.9-15.2\n",
      "822 203.87-161.9 | 161.9/100-120.6\n",
      "824 table_max(tier1capital,none) | \n",
      "828 2/5 | 2.0/100-5.0/100\n",
      "833 1000000/100*(311.81-100) | 100000*(311.81-100)\n",
      "834 8945694*40.85/1000000 | 766801*40.85/1000000\n",
      "835 318063+110457-(60224+77901) | 318063-60224\n",
      "837 85.05-81.99 | 85.05-70.18\n",
      "849 (5.8-6.3)/6.3 | 5.8-6.3\n",
      "851 49447-367 | 367-10354\n",
      "852 338501/3540009 | 3543016-253907\n",
      "854 210-182 | 210-7\n",
      "856 156.6/17.3-170.6/21.9 | 21.9*1000000-170.6*1000000\n",
      "858 38+-110+1 | 38-110\n",
      "859 (18.1-6.3-(14.6-5.2))/(14.6-5.2) | (18.1-14.6)/14.6\n",
      "863 127.1-70.4 | 127.1+70.4\n",
      "864 (856240-911507)/911507 | 856240/911507\n",
      "868 table_average(netsales,none) | \n",
      "869 5829-100 | 5829-154\n",
      "872 10.6+11 | 10.6+11.6+11.9\n",
      "876 (16.8-17.7)/17.7 | (19.1-22.3)/22.3\n",
      "878 7327-20963 | (496-20963)/20963\n",
      "879 5145+34526 | 5145+34526+337900\n",
      "882 110457/77901 | 121417/93200\n",
      "883 14.5/46.4 | 14.5*-1/31.9\n",
      "884 (217692-145095)/145095-100 | (217692-145095)/145095\n",
      "887 19.4+19.4+19.4 | 12.9*3\n",
      "888 217.56>296.67 | 235.63>217.56\n",
      "891 1.345*1000+30 | 1.345*1000*1000000\n",
      "892 table_min(alternativeinvestments,none) | \n",
      "895 (2.89+2.89+3)/3 | (2.89+2.89+2.89)/3\n",
      "896 612.5*1000000*(4.72/100) | 612.5*(4.4/100)/1000\n",
      "897 (1473+4218)/2 | 1473/4218\n",
      "902 69.8/(172099/1000) | 69.8/172099\n",
      "906 157/191 | 157/170\n",
      "908 587/2859 | 587/580\n",
      "909 (776-748)/748 | 776/773-1\n",
      "911 546.5-516.9 | 531.6-546.5\n",
      "913 705.4/703.1-1 | (705.4-703.1)/705.4\n",
      "918 (26.6-47.6)/47.6 | (134.6-37.3)/37.3\n",
      "921 3.79-3.68-100 | 3.79-3.68\n",
      "933 2/14.9 | -16.9--14.9\n",
      "936 (41.7+(24.0+28.8))/3 | (28.8+2.1+41.7)/3\n",
      "937 424+10202 | 10543-424000\n",
      "939 (66/100*28383-40/100*12099)/(40/100*12099) | (12099*(40/100)-28383*(66/100))/(28383*(66/100))\n",
      "942 265+-557 | 265+172\n",
      "947 (127.1-106.6)/106.6 | (148.9-166.8)/166.8\n",
      "948 17.0-18.9 | 7.7-31.3\n",
      "950 703.1+18.2 | 703.1-705.4+705.4\n",
      "953 217692/139255 | 217692*1000000*217692\n",
      "954 54/(52+(64+54)+19+16) | 54/75\n",
      "955 (77-55)/55 | 77-55\n",
      "959 table_average(protectcrackspreadvalues,none) | (1+5)/2\n",
      "960 88+4 | 88*2\n",
      "961 83539/1000/585.3 | 83539/585.3\n",
      "966 127.1-70.4 | 127.1+70.4\n",
      "967 203.4+(231.1+203.4)+3 | (231.1+203.4+221.1+3)/2\n",
      "976 7874/16044 | 7874/5183\n",
      "986 153644/2330532 | 0.2/2.3\n",
      "987 2.7/(31.2+2.7) | 31.2/30.1\n",
      "988 table_max(collateralposted,none) | \n",
      "992 1423/59677 | 1838/78975\n",
      "993 79.0/268.4 | 41.9/268.4\n",
      "995 1410.5-1229.0-1229.0 | (1410.5-1229.0)/1229.0\n",
      "999 558368-506032 | (558368-506032)/506032\n",
      "1002 (426932-341003)/341003 | 17.5/345777\n",
      "1003 156/15 | (156+15)/(156+15)\n",
      "1004 581+123 | 367-123\n",
      "1005 (24.98-15.32)/15.32 | (53210-50119)/50119\n",
      "1007 160.62/100 | (160.62-100)/100\n",
      "1008 10.6+11+11.2+11.6+11.9 | 10.6+11+(11.6+11.9)\n",
      "1010 301-665 | 84-2239\n",
      "1011 table_sum(accumulatedothercomprehensiveloss,none) | \n",
      "1013 (1.24-0.78)/0.78 | (1.61-0.98)/0.98\n",
      "1016 48/7.0 | 48/38\n",
      "1017 2.6-2.6 | 2.6-1.6\n",
      "1020 997/(7*1000) | 997/7.0*100\n",
      "1021 384102-78841 | 384102-121417\n",
      "1023 (2075-2068)/2068 | 2075/2068\n",
      "1025 353+6-32 | 32+353\n",
      "1028 3474/19941 | 3543/21813\n",
      "1030 4.8/212.7 | (73684*(6.25/100)-109435*(6.25/100))/(6.25/100)\n",
      "1032 60-50 | 50/100-60/100\n",
      "1035 875-848 | 848-1373\n",
      "1038 59677-17177 | 43097-17177\n",
      "1042 326.5+328.4+322.4+3 | (322.4+326.5+328.4)/3\n",
      "1044 9.3-8.4+8.4 | (9.3-8.4)/8.4\n",
      "1047 509-707-707 | (509-707)/707\n",
      "1052 (64350-40000)/40000 | (66000-40000)/40000\n",
      "1053 124/747 | 124/657\n",
      "1055 (534648-419651)/419651 | 534648/419651\n",
      "1059 (8690-7943)/7943 | (1840+6850)/1000*100\n",
      "1060 (2440+3237+4127)/(19941+21813+23988) | \n",
      "1063 433161/15973855 | 2143649/4915507\n",
      "1065 4489/22560 | 4489/23988\n",
      "1070 159/898 | 303/(2646+898)\n",
      "1075 155/898 | 378/(2646+898)\n",
      "1079 14-3 | 14-11\n",
      "1081 1277+-466+-515 | 1277+-472+-515\n",
      "1082 110.17*(1564746-1482914) | 1564746*110.17\n",
      "1084 (66000-64350)/64350 | (66000-40000)/40000\n",
      "1085 113.49*3629455 | 1708928*113.49\n",
      "1087 148-124 | 177-148\n",
      "1088 487-516 | 487-234\n",
      "1089 175/3081 | (150+175)/3081\n",
      "1092 1.3*3 | 1.3+1.4+1.5\n",
      "1093 170+7819 | 5822-1376\n",
      "1097 2/(8.2-2) | 2*1000/8.2\n",
      "1099 4074/20397 | 4074/21813\n",
      "1100 (342-301)/301 | (4.9-5.2)/5.2\n",
      "1105 (165172-222427)/222427 | 404380-974444\n",
      "1107 3063816*4 | 3063816*89.66\n",
      "1110 23/2329 | 23/692\n",
      "1111 (6.91-8.75)/8.75 | (8.05-6.91)/6.91\n",
      "1114 1.0*1000*(5.0/100) | 50*2.5\n",
      "1123 (348-259)/259 | (4.9-5.2)/5.2\n",
      "1124 56-34 | 122-56\n",
      "1126 3147/5545 | 2321/4244\n",
      "1129 262+-472+-102 | 262-1277\n",
      "1131 (8.05-6.91)/6.91 | (6.91-8.05)/8.05\n",
      "1133 (750+1000+750)/5700 | (750+1000)/5700\n",
      "1135 (5583333+5583333)/1000000 | 558333+558333\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "prog_correct = 0\n",
    "exec_correct = 0\n",
    "\n",
    "wrong_indices = []\n",
    "\n",
    "for i in range(len(translated_programs)):\n",
    "    t_prog = translated_programs[i].replace(\" \", \"\")\n",
    "    g_prog = gen_programs[i].replace(\" \", \"\")\n",
    "\n",
    "    if t_prog == g_prog:\n",
    "        prog_correct += 1\n",
    "\n",
    "    if if_exec_correct(t_prog, g_prog):\n",
    "        exec_correct += 1\n",
    "    else:\n",
    "        wrong_indices.append(i)\n",
    "        print(i, t_prog, \"|\", g_prog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6451612903225806, 0.5719267654751525)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "exec_correct / len(translated_programs), prog_correct / len(translated_programs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febf37aa7fd74de1af47426ed4e9b84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9577e8e4bc924387a35bd4f81ab191c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\"decapoda-research/llama-7b-hf\", device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "model_cpu = LlamaForCausalLM.from_pretrained(\"./llama-7b/checkpoint-1122\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "model.load_state_dict(model_cpu.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [00:04<00:00, 244.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
    "\n",
    "# %%\n",
    "all_input_ids = []\n",
    "\n",
    "for item in tqdm.tqdm(data):\n",
    "    table_md = convert_to_markdown(item[\"table_ori\"])\n",
    "    question = item[\"qa\"][\"question\"]\n",
    "    \n",
    "    pre_text = \"\\n\".join(item[\"pre_text\"])\n",
    "    post_text = \"\\n\".join(item[\"post_text\"])\n",
    "    \n",
    "    context = f\"{pre_text}\\n\\n{table_md}\\n\\n{post_text}\\n\\n\"\n",
    "    user_prompt = f\"### Context ###\\n\\n{context}### Question ###\\n\\n{question}\"\n",
    "    input_prompt = f\"### Instruction ###\\n\\n{system_prompt}\\n\\n{user_prompt}\\n\\n### Answer ###\\n\\n\"\n",
    "\n",
    "    input_ids = tokenizer.encode(input_prompt, add_special_tokens=False)\n",
    "\n",
    "    input_ids_length = len(input_ids) \n",
    "    max_seq_length = 1984 \n",
    "    while input_ids_length > max_seq_length:\n",
    "        # truncate the first input_ids_length - max_seq_length tokens\n",
    "        context = context.split(\" \")[input_ids_length - max_seq_length:]\n",
    "        context = \" \".join(context)\n",
    "        # recreate the input_text\n",
    "        user_prompt = f\"### Context ###\\n\\n{context}### Question ###\\n\\n{question}\"\n",
    "        input_prompt = f\"### Instruction ###\\n\\n{system_prompt}\\n\\n{user_prompt}\\n\\n### Answer ###\\n\\n\"\n",
    "\n",
    "        input_ids = tokenizer.encode(input_prompt, add_special_tokens=False)\n",
    "\n",
    "        input_ids_length = len(input_ids)\n",
    "\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "\n",
    "    all_input_ids.append(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [08:33<00:00,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "batch_size = 4\n",
    "\n",
    "responses = []\n",
    "\n",
    "for i in tqdm.tqdm(range(0, len(all_input_ids), batch_size)):\n",
    "    batch_input_ids = all_input_ids[i:i+batch_size]\n",
    "    batch_input_ids = [item.flip(0) for item in batch_input_ids]\n",
    "    batch_input_ids = pad_sequence(batch_input_ids, \n",
    "                                   batch_first=True,\n",
    "                                   padding_value=tokenizer.pad_token_id).to(model.device)\n",
    "    batch_input_ids = batch_input_ids.flip(1)\n",
    "\n",
    "    attention_mask = (batch_input_ids != tokenizer.pad_token_id).bool().to(model.device)\n",
    "\n",
    "    output = model.generate(batch_input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            do_sample=True,\n",
    "                            top_p=0.9, \n",
    "                            temperature=0.9, \n",
    "                            max_new_tokens=128, \n",
    "                            eos_token_id=tokenizer.eos_token_id, \n",
    "                            pad_token_id=tokenizer.eos_token_id, \n",
    "                            early_stopping=True)\n",
    "\n",
    "    for j in range(output.shape[0]):\n",
    "        input_ids_length = batch_input_ids.shape[1]\n",
    "        response = tokenizer.decode(output[j][input_ids_length:], skip_special_tokens=True)\n",
    "\n",
    "        responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "            \"responses\": responses,\n",
    "            \"model_name\": \"llama-7b-finetune-1122\",\n",
    "          }\n",
    "\n",
    "with open(\"./results/llama7b-finetune-1122.json\", \"w\") as f:\n",
    "    json.dump(result, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check llama_funetune pkl\n",
    "\n",
    "with open(\"./llama_finetune_dataset.pkl\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### Instruction ###\\n\\nYou need to answer the user's question in the ### Question ### section.\\nYou need to provide the answer in the format 'Calculate(a + b)', where the expression needs to be python excutable.For example, if the question is 'What is the sum of 1 + 2?', you need to answer 'Calculate(1 + 2)'.if the question is 'Is 123 greater than 231?', you need to answer 'Calculate(123 > 231)'.DO NOT give anything else other than'Calculate()'.\\n\\n### Context ###\\n\\ninterest rate to a variable interest rate based on the three-month libor plus 2.05% ( 2.05 % ) ( 2.34% ( 2.34 % ) as of october 31 , 2009 ) .\\nif libor changes by 100 basis points , our annual interest expense would change by $ 3.8 million .\\nforeign currency exposure as more fully described in note 2i .\\nin the notes to consolidated financial statements contained in item 8 of this annual report on form 10-k , we regularly hedge our non-u.s .\\ndollar-based exposures by entering into forward foreign currency exchange contracts .\\nthe terms of these contracts are for periods matching the duration of the underlying exposure and generally range from one month to twelve months .\\ncurrently , our largest foreign currency exposure is the euro , primarily because our european operations have the highest proportion of our local currency denominated expenses .\\nrelative to foreign currency exposures existing at october 31 , 2009 and november 1 , 2008 , a 10% ( 10 % ) unfavorable movement in foreign currency exchange rates over the course of the year would not expose us to significant losses in earnings or cash flows because we hedge a high proportion of our year-end exposures against fluctuations in foreign currency exchange rates .\\nthe market risk associated with our derivative instruments results from currency exchange rate or interest rate movements that are expected to offset the market risk of the underlying transactions , assets and liabilities being hedged .\\nthe counterparties to the agreements relating to our foreign exchange instruments consist of a number of major international financial institutions with high credit ratings .\\nwe do not believe that there is significant risk of nonperformance by these counterparties because we continually monitor the credit ratings of such counterparties .\\nwhile the contract or notional amounts of derivative financial instruments provide one measure of the volume of these transactions , they do not represent the amount of our exposure to credit risk .\\nthe amounts potentially subject to credit risk ( arising from the possible inability of counterparties to meet the terms of their contracts ) are generally limited to the amounts , if any , by which the counterparties 2019 obligations under the contracts exceed our obligations to the counterparties .\\nthe following table illustrates the effect that a 10% ( 10 % ) unfavorable or favorable movement in foreign currency exchange rates , relative to the u.s .\\ndollar , would have on the fair value of our forward exchange contracts as of october 31 , 2009 and november 1 , 2008: .\\n\\n||October 31, 2009|November 1, 2008|\\n|---|---|---|\\n|Fair value of forward exchange contracts asset (liability)|$6,427|$(23,158)|\\n|Fair value of forward exchange contracts after a 10% unfavorable movement in foreign currency exchange rates asset (liability)|$20,132|$(9,457)|\\n|Fair value of forward exchange contracts after a 10% favorable movement in foreign currency exchange rates liability|$(6,781)|$(38,294)|\\n\\n\\nfair value of forward exchange contracts after a 10% ( 10 % ) unfavorable movement in foreign currency exchange rates asset ( liability ) .\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n$ 20132 $ ( 9457 ) fair value of forward exchange contracts after a 10% ( 10 % ) favorable movement in foreign currency exchange rates liability .\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n$ ( 6781 ) $ ( 38294 ) the calculation assumes that each exchange rate would change in the same direction relative to the u.s .\\ndollar .\\nin addition to the direct effects of changes in exchange rates , such changes typically affect the volume of sales or the foreign currency sales price as competitors 2019 products become more or less attractive .\\nour sensitivity analysis of the effects of changes in foreign currency exchange rates does not factor in a potential change in sales levels or local currency selling prices. .\\n\\n### Question ###\\n\\nwhat is the the interest expense in 2009?\\n\\n### Answer ###\\n\\n  Calculate(3.8 / (100 / 100))\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e71e7a8d8e31deccf5d1eddc2d2f4cf87258536331571f1485f65dc30eadcbc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
