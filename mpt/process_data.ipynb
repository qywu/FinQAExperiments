{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Any, List, Dict, Mapping, Tuple, Union, Optional\n",
    "import copy\n",
    "from dataclasses import dataclass, field\n",
    "import json\n",
    "import pathlib\n",
    "from typing import Dict, Optional, Sequence\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "import transformers\n",
    "from transformers import Trainer\n",
    "from transformers.trainer_pt_utils import LabelSmoother\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418e4a50263a440da801b89c3ea8bd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733396bc43c741ccbe8335b6c0e9c74e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aec7b7840e24ae2abce45862e783c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mosaicml/mpt-7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../finetune_data_prepared.jsonl\") as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6203/6203 [00:18<00:00, 333.59it/s]\n"
     ]
    }
   ],
   "source": [
    "all_examples = []\n",
    "\n",
    "for item in tqdm.tqdm(data):\n",
    "    prompt = item[\"prompt\"]\n",
    "    answer = item[\"completion\"]\n",
    "\n",
    "    prompt_ids = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "    answer_ids = tokenizer.encode(answer, add_special_tokens=False) + [tokenizer.eos_token_id]\n",
    "\n",
    "    input_ids = torch.tensor(prompt_ids + answer_ids, dtype=torch.long)\n",
    "\n",
    "    if len(input_ids) > 2048:\n",
    "        print(\"skipping\", len(input_ids))\n",
    "        continue\n",
    "\n",
    "    labels = input_ids.clone()\n",
    "    labels[: len(prompt_ids)] = -100\n",
    "\n",
    "    all_examples.append(\n",
    "        dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=torch.ones_like(input_ids, dtype=torch.bool),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./mpt_finetune_dataset.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_examples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e71e7a8d8e31deccf5d1eddc2d2f4cf87258536331571f1485f65dc30eadcbc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
